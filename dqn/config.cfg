general:
  num_experiments: 1
  num_episodes: 2000
  num_actions: 4
  max_steps: 100
  confusion_dim: 10
  num_actual_state: 10
  state_dim: 20
  action_dim: 1
  good_terminal_state: 9
  bad_terminal_state: 8

explorer_params:
  epsilon: .5
  decay: .99995

learning_params:
  discount: .99
  learning_rate: .5
  learning_rate_end: 0.0
  learning_decay: 0.999995
  minibatch_size: 10
  replay_max_size: 100  # size of replay pool
  rescale_reward: False
  reward_divider: 1.0
  update_freq: 5
  ddqn: True
